# Robotic Speech
- "speech_v1" contains a simple example of voice recognition, and generic text to speech output. To use, download and run the file.
- "speech_v2" contains a complex example of vocal synthesis in place of the generic TTS seen in speech_v1. To use this version, the user must obtain the appropriate json file api-key from Google, and enable the TTS module through Google's website by entering a payment method. If done correctly, the user has the option to choose either the "standard" TTS or the "wavenet" TTS. Wavenet is better, but costs most ($16 per 1 million characters synthesized, billed monthly).
- "speech_v3" contains the first iteration of the ibm watson assistant integration. It is able to connect directly to an assistant in order to form a response. API key, assistant version date, assistant service url, assistant id, and session id are needed to make the connection work. Note that when new intents/dialog are added to the assistant online, they will become immidiately available through the api connection in the program (no delay time).
- "speech_v4" now implements the "hey charlie" activation keyword. There are 2 kinds of activation: either "hey charlie" by itself which invokes a second input to ask charlie, or "hey charlie (rest of string to ask charlie here)" which will instead not invoke a second input but will parse out the rest of the string after 'hey charlie' and use that as the input.
- "speech_v5" fixes some parsing issues with creating the session and handling other json objects. This fix also allows linux to handle both the speech recognition and watson assistant.
- "speech_v8" removes the use of facial recognition (due to COVID-19 with masks) and implements custom voice configuration using the Google Cloud Text-to-Speech API. Using the "hey charlie" activation keyword now plays a sound as a signal for Charlie to begin listening for follow-up statements.